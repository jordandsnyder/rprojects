---
title: "Alex Blog Analysis"
output: html_notebook
---

I wish to do the following:

1. Download entries from my buddies blogs.
2. Take the information and process/clean it into tidy text format.
3. Analyze findings.

In the future, I wish to add the following:
a. Create a Shiny Interactive Dashboard.
b. Create an automated email/update on a regular (e.g., weekly or monthly basis)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loadlibraries}
library(rvest)
library(tidyverse)
```

```{r read alexblog}

if(!exists("all_entries"))
   {
  source("scripts/1 - download.R")
  
} else {
  
  source("scripts/2 - load.R")
  
}

```

```{r new}


driver <- read_html("")

subURLs <- html_nodes(driver,'td') %>% 
            html_children() %>% 
            html_attr('href')

allurls <- paste(mainURL, subURLs, sep = "")

allurls


for





# This function fetches those four entities as you learned in the previous section of this guide
entity <- function(s){
  
  # Course Title
  # Since Number of Courses may differ from Skill to Skill, therefore,
  # we have done dynamic fetching of the course names
  
  subtitle <- html_nodes(s, "h2") %>%
    html_text() 
  
  body <- html_nodes(s, "p") %>% html_text()
  
  return(text)
}


# A for loop which goes through all the URLs, fetch the entities and display them on the screen 
i = 1
for (i in 1:10) {
  subDriver <- read_html(paste(mainURL, subURLs[i], sep = ""))
  print(entity(subDriver))
}


```
